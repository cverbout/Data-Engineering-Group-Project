# This viminfo file was generated by Vim 9.0.
# You may edit it if you're careful!

# Viminfo version
|1,4

# Value of 'encoding' when this file was written
*encoding=utf-8


# hlsearch on (H) or off (h):
~h
# Last Search Pattern:
~MSle0~/breadcrumb

# Command Line History (newest to oldest):
:wqa
|2,0,1715116962,,"wqa"
:qa
|2,0,1715116923,,"qa"
:q
|2,0,1714610000,,"q"
:wq
|2,0,1713380009,,"wq"

# Search String History (newest to oldest):
?/breadcrumb
|2,1,1714620733,47,"breadcrumb"
?/print
|2,1,1713380007,47,"print"
? \<CloudLoggingHandler\>
|2,1,1713371302,,"\\<CloudLoggingHandler\\>"
? \<py\>
|2,1,1712982859,,"\\<py\\>"
? \<0\>
|2,1,1712982853,,"\\<0\\>"

# Expression History (newest to oldest):

# Input Line History (newest to oldest):

# Debug Line History (newest to oldest):

# Registers:
"0	CHAR	0
	import requests
	import pandas as pd
	from datetime import datetime
	import json
	import time
	from tqdm import tqdm
	from google.cloud import storage
	
	
	
	def get_vehicle_ids():
	    doc_key = "10VKMye65LhbEgMLld5Ol3lOocWUwCaEgnPVgFQf9em0"
	    url = f"https://docs.google.com/spreadsheets/d/{doc_key}/export?format=csv"
	    response = requests.get(url)
	    csv_data = response.content
	    with open("vehicle_ids_sheet.csv", "wb") as file:
	        file.write(csv_data)
	    vehicle_ids = pd.read_csv("vehicle_ids_sheet.csv")['Doodle'].tolist()
	    return vehicle_ids
	
	def save_to_gcs(data, filename):
	    bucket_name = 'cs510-spring24-project1-bucket'
	    folder_name = "data_via_direct_download"
	    bucket_path = f"gs://{bucket_name}/{folder_name}/"
	    client = storage.Client.from_service_account_json('cs510-project1-6c1b06b5846a.json')
	    bucket = client.bucket(bucket_path)
	    blob = bucket.blob(filename)
	    blob.upload_from_string(json.dumps(data), content_type='application/json')
	    print(f"Data saved successfully to GCS with filename {filename}")
	
	def save_trimet_doodle_data():
	    vehicle_ids = get_vehicle_ids()
	    all_breadcrumbs = {}
	
	    for i, vehicle_id in enumerate(tqdm(vehicle_ids, desc="Processing vehicle IDs")):
	        index_str = f"[{i+1:03}/{len(vehicle_ids):03}]"
	        success = False
	        attempts = 0
	        while not success and attempts < 5:
	            url = f"https://busdata.cs.pdx.edu/api/getBreadCrumbs?vehicle_id={vehicle_id}"
	            response = requests.get(url)
	            attempts += 1
	            if response.status_code == 200:
	                all_breadcrumbs[vehicle_id] = response.json()
	                print(f"{index_str} Successfully fetched data for vehicle ID {vehicle_id}")
	                success = True
	            time.sleep(1)
	        if not success:
	            all_breadcrumbs[vehicle_id] = []
	            print(f"{index_str} Failed to get data after 5 attempts for vehicle ID {vehicle_id}")
|3,0,0,0,50,0,1713287924,"import requests","import pandas as pd","from datetime import datetime","import json","import time","from tqdm import tqdm","from google.cloud import storage","","","","def get_vehicle_ids():","    doc_key = \"10VKMye65LhbEgMLld5Ol3lOocWUwCaEgnPVgFQf9em0\"","    url = f\"https://docs.google.com/spreadsheets/d/{doc_key}/export?format=csv\"","    response = requests.get(url)","    csv_data = response.content",>59
|<"    with open(\"vehicle_ids_sheet.csv\", \"wb\") as file:","        file.write(csv_data)","    vehicle_ids = pd.read_csv(\"vehicle_ids_sheet.csv\")['Doodle'].tolist()","    return vehicle_ids","","def save_to_gcs(data, filename):","    bucket_name = 'cs510-spring24-project1-bucket'","    folder_name = \"data_via_direct_download\"","    bucket_path = f\"gs://{bucket_name}/{folder_name}/\"","    client = storage.Client.from_service_account_json('cs510-project1-6c1b06b5846a.json')",>41
|<"    bucket = client.bucket(bucket_path)","    blob = bucket.blob(filename)","    blob.upload_from_string(json.dumps(data), content_type='application/json')","    print(f\"Data saved successfully to GCS with filename {filename}\")","","def save_trimet_doodle_data():","    vehicle_ids = get_vehicle_ids()","    all_breadcrumbs = {}","","    for i, vehicle_id in enumerate(tqdm(vehicle_ids, desc=\"Processing vehicle IDs\")):","        index_str = f\"[{i+1:03}/{len(vehicle_ids):03}]\"",>25
|<"        success = False","        attempts = 0","        while not success and attempts < 5:","            url = f\"https://busdata.cs.pdx.edu/api/getBreadCrumbs?vehicle_id={vehicle_id}\"","            response = requests.get(url)","            attempts += 1","            if response.status_code == 200:","                all_breadcrumbs[vehicle_id] = response.json()","                print(f\"{index_str} Successfully fetched data for vehicle ID {vehicle_id}\")",>32
|<"                success = True","            time.sleep(1)","        if not success:","            all_breadcrumbs[vehicle_id] = []","            print(f\"{index_str} Failed to get data after 5 attempts for vehicle ID {vehicle_id}\")"
""1	LINE	0
	# The rest of your code...
|3,1,1,1,1,0,1715116960,"# The rest of your code..."
"2	LINE	0
	def upload_json_to_database(json_files):
	    uploaded_entries = {}  # Start with an empty dictionary
	    if os.path.exists(LOCAL_JSON_RECORD):
	        with open(LOCAL_JSON_RECORD, 'r') as file:
	            file_contents = file.read()  # Read the contents
	            if file_contents:  # Check if the contents are non-empty
	                uploaded_entries = json.loads(file_contents)  # Load JSON data
	            else:
	                uploaded_entries = {}  # Initialize as empty if the file is empty
	
	    pbar = tqdm(json_files, desc="Uploading JSON data")
	    for json_file in pbar:
	        with open(json_file, 'r') as file:
	            data = json.load(file)
	            for vehicle_id, events in data.items():
	                file_vehicle_id = json_file + "_" + str(vehicle_id)
	                if file_vehicle_id not in uploaded_entries:
	                    impute_gps_coordinates(events)
	                    try:
	                        db_up.insert_breadcrumb(events)
	                        uploaded_entries[file_vehicle_id] = True
	                    except Exception as e:
	                        print(f"Error processing {json_file} for vehicle {vehicle_id}: {e}")
	                        continue
	            pbar.set_description(f"Processed {json_file}")
	
	        # Update the progress file
	        with open(LOCAL_JSON_RECORD, 'w') as file:
	            json.dump(uploaded_entries, file)
|3,0,2,1,29,0,1715116956,"def upload_json_to_database(json_files):","    uploaded_entries = {}  # Start with an empty dictionary","    if os.path.exists(LOCAL_JSON_RECORD):","        with open(LOCAL_JSON_RECORD, 'r') as file:","            file_contents = file.read()  # Read the contents","            if file_contents:  # Check if the contents are non-empty","                uploaded_entries = json.loads(file_contents)  # Load JSON data","            else:",>83
|<"                uploaded_entries = {}  # Initialize as empty if the file is empty","","    pbar = tqdm(json_files, desc=\"Uploading JSON data\")","    for json_file in pbar:","        with open(json_file, 'r') as file:","            data = json.load(file)","            for vehicle_id, events in data.items():","                file_vehicle_id = json_file + \"_\" + str(vehicle_id)","                if file_vehicle_id not in uploaded_entries:",>52
|<"                    impute_gps_coordinates(events)","                    try:","                        db_up.insert_breadcrumb(events)","                        uploaded_entries[file_vehicle_id] = True","                    except Exception as e:","                        print(f\"Error processing {json_file} for vehicle {vehicle_id}: {e}\")","                        continue","            pbar.set_description(f\"Processed {json_file}\")","","        # Update the progress file",>52
|<"        with open(LOCAL_JSON_RECORD, 'w') as file:","            json.dump(uploaded_entries, file)"
"3	LINE	0
	TriMet__2024-04-11.json
|3,0,3,1,1,0,1715116719,"TriMet__2024-04-11.json"
"4	LINE	0
	
|3,0,4,1,1,0,1715116634,""
"5	LINE	0
	# The rest of your code...
|3,0,5,1,1,0,1715116634,"# The rest of your code..."
"6	LINE	0
	def upload_json_to_database(json_files):
	    # Dictionary to store progress
	    uploaded_entries = {}
	    if os.path.exists(LOCAL_JSON_RECORD):
	        with open(LOCAL_JSON_RECORD, 'r') as file:
	            uploaded_entries = json.load(file)
	
	    pbar = tqdm(json_files, desc="Uploading JSON data")
	    for json_file in pbar:
	        with open(json_file, 'r') as file:
	            data = json.load(file)
	            for vehicle_id, events in data.items():
	                file_vehicle_id = json_file + "_" + str(vehicle_id)
	                if file_vehicle_id not in uploaded_entries:
	                    impute_gps_coordinates(events)
	                    try:
	                        db_up.insert_breadcrumb(events)
	                        # Update the record after successful upload
	                        uploaded_entries[file_vehicle_id] = True
	                    except Exception as e:
	                        print(f"Error processing {json_file} for vehicle {vehicle_id}: {e}")
	                        continue
	            pbar.set_description(f"Processed {json_file}")
	        # Update the progress file
	        with open(LOCAL_JSON_RECORD, 'w') as file:
	            json.dump(uploaded_entries, file)
	
|3,0,6,1,27,0,1715116628,"def upload_json_to_database(json_files):","    # Dictionary to store progress","    uploaded_entries = {}","    if os.path.exists(LOCAL_JSON_RECORD):","        with open(LOCAL_JSON_RECORD, 'r') as file:","            uploaded_entries = json.load(file)","","    pbar = tqdm(json_files, desc=\"Uploading JSON data\")","    for json_file in pbar:","        with open(json_file, 'r') as file:","            data = json.load(file)",>53
|<"            for vehicle_id, events in data.items():","                file_vehicle_id = json_file + \"_\" + str(vehicle_id)","                if file_vehicle_id not in uploaded_entries:","                    impute_gps_coordinates(events)","                    try:","                        db_up.insert_breadcrumb(events)","                        # Update the record after successful upload","                        uploaded_entries[file_vehicle_id] = True",>44
|<"                    except Exception as e:","                        print(f\"Error processing {json_file} for vehicle {vehicle_id}: {e}\")","                        continue","            pbar.set_description(f\"Processed {json_file}\")","        # Update the progress file","        with open(LOCAL_JSON_RECORD, 'w') as file:","            json.dump(uploaded_entries, file)",""
"7	LINE	0
	def upload_json_to_database(json_files):
	    uploaded_files = set()
	    if os.path.exists(LOCAL_JSON_RECORD):
	        with open(LOCAL_JSON_RECORD, 'r') as file:
	            uploaded_files = set(file.read().splitlines())
	
	    pbar = tqdm(json_files, desc="Uploading JSON data")
	    
	    for json_file in pbar:
	        if json_file not in uploaded_files:
	            with open(json_file, 'r') as file:
	                data = json.load(file)
	                for vehicle_id, events in data.items():
	                    impute_gps_coordinates(events)
	                    try:
	                        db_up.insert_breadcrumb(events)
	                    except Exception as e:
	                        print(f"Error processing {json_file} for vehicle {vehicle_id}: {e}")
	            with open(LOCAL_JSON_RECORD, 'a') as file:
	                file.write(json_file + '\n')
	            pbar.set_description(f"Uploaded {json_file}")
	        else:
	            pbar.set_description(f"Skipped {json_file} (already uploaded)")
|3,0,7,1,23,0,1715116365,"def upload_json_to_database(json_files):","    uploaded_files = set()","    if os.path.exists(LOCAL_JSON_RECORD):","        with open(LOCAL_JSON_RECORD, 'r') as file:","            uploaded_files = set(file.read().splitlines())","","    pbar = tqdm(json_files, desc=\"Uploading JSON data\")","    ","    for json_file in pbar:","        if json_file not in uploaded_files:","            with open(json_file, 'r') as file:",>40
|<"                data = json.load(file)","                for vehicle_id, events in data.items():","                    impute_gps_coordinates(events)","                    try:","                        db_up.insert_breadcrumb(events)","                    except Exception as e:","                        print(f\"Error processing {json_file} for vehicle {vehicle_id}: {e}\")","            with open(LOCAL_JSON_RECORD, 'a') as file:","                file.write(json_file + '\\n')",>61
|<"            pbar.set_description(f\"Uploaded {json_file}\")","        else:","            pbar.set_description(f\"Skipped {json_file} (already uploaded)\")"
"8	LINE	0
	# Ignore the Google Cloud service account key
	cs510-project1-6c1b06b5846a.json
	
	# Ignore Python environment folder
	myenv/
	
	# Ignore compiled Python files
	*.pyc
	
	# Ignore log files and directories
	*.log
	logs/
	
	# Ignore data files that may contain sensitive or large data
	*.csv
	*.json
	
|3,0,8,1,17,0,1715114473,"# Ignore the Google Cloud service account key","cs510-project1-6c1b06b5846a.json","","# Ignore Python environment folder","myenv/","","# Ignore compiled Python files","*.pyc","","# Ignore log files and directories","*.log","logs/","","# Ignore data files that may contain sensitive or large data","*.csv","*.json",""
"9	LINE	0
	TriMet__2024-04-11.json
|3,0,9,1,1,0,1714623026,"TriMet__2024-04-11.json"
"-	CHAR	0
	'cs510-project1-6c1b06b5846a.json'
|3,0,36,0,1,0,1713289532,"'cs510-project1-6c1b06b5846a.json'"

# File marks:
'0  106  0  ~/from_bucket_to_database.py
|4,48,106,0,1715116962,"~/from_bucket_to_database.py"
'1  1  0  ~/uploaded_json_records.txt
|4,49,1,0,1715116923,"~/uploaded_json_records.txt"
'2  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,50,14,0,1715116743,"~/cs510-project1-6c1b06b5846a.json"
'3  1  0  ~/uploaded_json_records.txt
|4,51,1,0,1715116720,"~/uploaded_json_records.txt"
'4  98  0  ~/from_bucket_to_database.py
|4,52,98,0,1715116635,"~/from_bucket_to_database.py"
'5  68  0  ~/from_bucket_to_database.py
|4,53,68,0,1715116409,"~/from_bucket_to_database.py"
'6  95  0  ~/from_bucket_to_database.py
|4,54,95,0,1715116409,"~/from_bucket_to_database.py"
'7  22  0  ~/.gitignore
|4,55,22,0,1715114477,"~/.gitignore"
'8  27  0  ~/cs510-project1-6c1b06b5846a.json
|4,56,27,0,1715114312,"~/cs510-project1-6c1b06b5846a.json"
'9  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,57,14,0,1715114312,"~/cs510-project1-6c1b06b5846a.json"

# Jumplist (newest first):
-'  106  0  ~/from_bucket_to_database.py
|4,39,106,0,1715116962,"~/from_bucket_to_database.py"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116923,"~/uploaded_json_records.txt"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116923,"~/uploaded_json_records.txt"
-'  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,14,0,1715116743,"~/cs510-project1-6c1b06b5846a.json"
-'  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,14,0,1715116743,"~/cs510-project1-6c1b06b5846a.json"
-'  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,14,0,1715116743,"~/cs510-project1-6c1b06b5846a.json"
-'  14  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,14,0,1715116743,"~/cs510-project1-6c1b06b5846a.json"
-'  1  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,1,0,1715116733,"~/cs510-project1-6c1b06b5846a.json"
-'  1  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,1,0,1715116733,"~/cs510-project1-6c1b06b5846a.json"
-'  1  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,1,0,1715116733,"~/cs510-project1-6c1b06b5846a.json"
-'  1  0  ~/cs510-project1-6c1b06b5846a.json
|4,39,1,0,1715116733,"~/cs510-project1-6c1b06b5846a.json"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116720,"~/uploaded_json_records.txt"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116720,"~/uploaded_json_records.txt"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116720,"~/uploaded_json_records.txt"
-'  1  0  ~/uploaded_json_records.txt
|4,39,1,0,1715116720,"~/uploaded_json_records.txt"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  98  0  ~/from_bucket_to_database.py
|4,39,98,0,1715116635,"~/from_bucket_to_database.py"
-'  68  0  ~/from_bucket_to_database.py
|4,39,68,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  95  0  ~/from_bucket_to_database.py
|4,39,95,0,1715116409,"~/from_bucket_to_database.py"
-'  118  0  ~/from_bucket_to_database.py
|4,39,118,0,1715116352,"~/from_bucket_to_database.py"
-'  115  0  ~/from_bucket_to_database.py
|4,39,115,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  110  0  ~/from_bucket_to_database.py
|4,39,110,0,1715116352,"~/from_bucket_to_database.py"
-'  107  0  ~/from_bucket_to_database.py
|4,39,107,0,1715116352,"~/from_bucket_to_database.py"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"
-'  22  0  ~/.gitignore
|4,39,22,0,1715114477,"~/.gitignore"

# History of marks within files (newest to oldest):

> ~/from_bucket_to_database.py
	*	1715116961	0
	"	106	0
	^	105	0
	.	105	0
	+	1	39
	+	1	13
	+	1	47
	+	1	14
	+	1	0
	+	1	38
	+	1	0
	+	1	33
	+	1	13
	+	1	0
	+	1	63
	+	1	0
	+	1	40
	+	1	68
	+	1	20
	+	1	0
	+	1	62
	+	1	40
	+	117	39
	+	106	0
	+	106	45
	+	106	0
	+	68	40
	+	105	0

> ~/uploaded_json_records.txt
	*	1715116922	0
	"	1	0
	.	1	0
	+	1	0

> ~/cs510-project1-6c1b06b5846a.json
	*	1715116742	0
	"	14	0
	^	14	0
	.	13	1
	+	52	1
	+	39	1
	+	26	1
	+	13	1

> ~/.gitignore
	*	1715114477	0
	"	22	0
	^	22	0
	.	21	7
	+	1	21
	+	21	7

> ~/breadcrumb_counter.py
	*	1714621072	0
	"	61	0
	^	61	0
	.	60	54
	+	44	0
	+	60	54

> ~/database_uploader.py
	*	1714619634	0
	"	63	0
	^	63	0
	.	62	20
	+	64	0
	+	36	0
	+	62	20

> ~/from_messages_to_database.py
	*	1714610173	0
	"	57	0

> ~/testing_breadcrumb_table.py
	*	1714610059	0
	"	30	0

> ~/topic_clean.py
	*	1713825062	0
	"	4	36
	^	4	37
	.	4	37
	+	19	85
	+	4	37

> ~/recieve_breadcrumb_messages.py
	*	1713823646	0
	"	42	8
	^	42	9
	.	42	8
	+	1	0
	+	1	5
	+	1	27
	+	1	61
	+	1	13
	+	1	31
	+	1	59
	+	1	84
	+	1	56
	+	1	31
	+	1	0
	+	1	36
	+	1	37
	+	1	9
	+	1	69
	+	1	42
	+	1	82
	+	1	42
	+	1	82
	+	1	42
	+	1	29
	+	1	0
	+	1	83
	+	1	42
	+	1	29
	+	1	26
	+	1	61
	+	1	0
	+	1	124
	+	1	0
	+	1	43
	+	1	42
	+	1	29
	+	1	59
	+	1	98
	+	1	0
	+	1	32
	+	1	42
	+	1	83
	+	1	58
	+	1	76
	+	1	63
	+	1	12
	+	1	90
	+	1	0
	+	1	89
	+	1	26
	+	1	0
	+	1	145
	+	1	28
	+	1	0
	+	1	42
	+	80	28
	+	71	0
	+	43	52
	+	42	8

> ~/publish_breadcrumb_messages.py
	*	1713822344	0
	"	24	0
	^	39	25
	.	39	24
	+	1	76
	+	1	22
	+	1	15
	+	1	25
	+	1	15
	+	39	24

> ~/receive_breadcrumbs.log
	*	1713808473	0
	"	1	0

> ~/cron_output.log
	*	1713473229	0
	"	838	0

> ~/project1_data_collection.py
	*	1713398663	0
	"	56	22
	^	56	23
	.	56	23
	+	1	15
	+	1	29
	+	1	0
	+	1	62
	+	1	115
	+	1	15
	+	61	29
	+	48	0
	+	8	0
	+	25	48
	+	23	0
	+	25	0
	+	27	37
	+	23	42
	+	25	52
	+	23	43
	+	24	13
	+	25	54
	+	24	17
	+	25	63
	+	45	16
	+	50	13
	+	45	17
	+	53	59
	+	54	0
	+	52	32
	+	56	23

> ~/contab
	*	1713389780	0
	"	1	0

> /tmp/crontab.q8DEVN/crontab
	*	1712984424	0
	"	23	0
	^	23	1
	.	23	0
	+	23	0

> /tmp/crontab.qF0lfv/crontab
	*	1712983884	0
	"	24	0
	^	24	0
	.	23	114
	+	22	0
	+	23	114

> /tmp/crontab.y3zfCw/crontab
	*	1712983606	0
	"	23	0
	^	23	0
	.	22	114
	+	21	0
	+	22	114

> /tmp/crontab.iDcitz/crontab
	*	1712982869	0
	"	22	0
	^	22	0
	.	21	79
	+	20	0
	+	21	79

> /tmp/crontab.TMA8Ly/crontab
	*	1712982633	0
	"	20	0
	^	21	0
	.	20	77
	+	22	0
	+	19	25
	+	20	77
